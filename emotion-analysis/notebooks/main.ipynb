{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internal Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX Backend:  gpu\n",
      "JAX Version:  0.4.23\n",
      "Python:  3.11.0 (main, Oct  4 2023, 22:00:02) [GCC 13.2.1 20230801]\n",
      "System:  posix.uname_result(sysname='Linux', nodename='archlinux', release='6.7.0-arch3-1', version='#1 SMP PREEMPT_DYNAMIC Sat, 13 Jan 2024 14:37:14 +0000', machine='x86_64')\n"
     ]
    }
   ],
   "source": [
    "# Find \".env\" file and add the package to $PATH\n",
    "import os, sys\n",
    "import typing as t\n",
    "from typing import Dict, TypeAlias, Any\n",
    "from dotenv import find_dotenv\n",
    "sys.path.append(os.path.dirname(find_dotenv()))\n",
    "\n",
    "# Use local package for modularity\n",
    "import emotion_analysis as ea\n",
    "from emotion_analysis import config\n",
    "from emotion_analysis.data.dataset import ECACDataset\n",
    "from emotion_analysis.model.trainer import TrainerModule\n",
    "from emotion_analysis.data.loader import DefaultDataLoader\n",
    "from emotion_analysis.model.pretrained import load_text_model\n",
    "from emotion_analysis.model.model import EmotionCauseTextModel\n",
    "from emotion_analysis.data.types import TrainSplit, DataSplit, SubTask\n",
    "from emotion_analysis.data.transform import DataTokenize, DataTransform, DataCollator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "External Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrm\n",
    "from jax import Array\n",
    "import jax.tree_util as tree_util\n",
    "from jax.tree_util import tree_structure\n",
    "from jax.typing import ArrayLike, DTypeLike\n",
    "import flax\n",
    "import flax.linen as nn\n",
    "import numpy as np\n",
    "import optax as opt\n",
    "import evaluate as eval\n",
    "import mlflow as mlf\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessors\n",
    "text_encoder_pretrained = load_text_model(config.model_repo, config.cache_dir)\n",
    "tokenizer = text_encoder_pretrained.tokenizer\n",
    "tokenize = DataTokenize( tokenizer,  max_seq_len=config.max_uttr_len)\n",
    "transform = DataTransform(tokenize, max_conv_len=config.max_conv_len)\n",
    "collator = DataCollator(transform)\n",
    "\n",
    "# Load data subsets\n",
    "dataset: Dict[DataSplit, ECACDataset] = ECACDataset.read_data(config.data_dir, config.subtask)\n",
    "ds_train, ds_valid, ds_test = *random_split(dataset['train'], [0.75, 0.25]), dataset['test']\n",
    "num_classes: int = dataset['train'].num_emotions\n",
    "\n",
    "# Train: drop_last=True to avoid JAX graph recompilation\n",
    "dataloader: t.Dict[TrainSplit, DataLoader[t.Dict[str, Array]]] = {\n",
    "    'train': DefaultDataLoader(ds_train,  shuffle=True, collate_fn=collator, drop_last=True),\n",
    "    'valid': DefaultDataLoader(ds_valid, shuffle=False, collate_fn=collator),\n",
    "    'test' : DefaultDataLoader( ds_test, shuffle=False, collate_fn=collator),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jrm.PRNGKey(config.seed)\n",
    "key, trainer_key = jrm.split(key, 2)\n",
    "f1_score = eval.load('f1')\n",
    "accuracy = eval.load('accuracy')\n",
    "\n",
    "trainer = TrainerModule(\n",
    "    key=trainer_key,\n",
    "    finetune=config.finetune,\n",
    "    batch_size=config.batch_size,\n",
    "    max_conv_len=config.max_conv_len,\n",
    "    max_uttr_len=config.max_uttr_len,\n",
    "    text_model_repo=config.model_repo,\n",
    "    learning_rate=config.learning_rate,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_until_index(array, index):\n",
    "    output = []\n",
    "    for batch, pad_idx in enumerate(index):\n",
    "        output.append(array[batch, :pad_idx, ...])\n",
    "    output = jnp.concatenate(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 32 :  1.0125986\n",
      "2 32 :  2.0120068\n",
      "3 32 :  1.0018982\n",
      "4 32 :  0.9496703\n",
      "5 32 :  1.2052962\n",
      "6 32 :  1.0290931\n",
      "7 32 :  0.56536543\n",
      "8 32 :  0.6995568\n",
      "9 32 :  0.7244954\n",
      "10 32 :  0.5673435\n",
      "11 32 :  0.6165367\n",
      "12 32 :  0.62261796\n",
      "13 32 :  0.64360917\n",
      "14 32 :  0.7007814\n",
      "15 32 :  0.65691155\n",
      "16 32 :  0.7357431\n",
      "17 32 :  0.49557114\n",
      "18 32 :  0.6283635\n",
      "19 32 :  0.73973775\n",
      "20 32 :  0.50049025\n",
      "21 32 :  0.52500874\n",
      "22 32 :  0.57250863\n",
      "23 32 :  0.5440023\n",
      "24 32 :  0.5248589\n",
      "25 32 :  0.5903663\n",
      "26 32 :  0.47550568\n",
      "27 32 :  0.4767759\n",
      "28 32 :  0.53062516\n",
      "29 32 :  0.59193736\n",
      "30 32 :  0.5174201\n",
      "31 32 :  0.4778231\n",
      "32 32 :  0.5792128\n",
      "train 0: {'f1': 0.29666067746653585}  f1\n",
      "train 0: {'accuracy': 0.33894984326018807} acc\n",
      "valid 0: 0.49913614988327026 loss\n",
      "valid 0: {'f1': 0.28701135494218755}  f1\n",
      "valid 0: {'accuracy': 0.40701128936423053} acc\n",
      "1 32 :  0.49877405\n",
      "2 32 :  0.5846058\n",
      "3 32 :  0.39293116\n",
      "4 32 :  0.42798916\n",
      "5 32 :  0.40629077\n",
      "6 32 :  0.59398454\n",
      "7 32 :  0.4783363\n",
      "8 32 :  0.49434924\n",
      "9 32 :  0.4656752\n",
      "10 32 :  0.4685247\n",
      "11 32 :  0.53872275\n",
      "12 32 :  0.45762306\n",
      "13 32 :  0.46750647\n",
      "14 32 :  0.419742\n",
      "15 32 :  0.4990241\n",
      "16 32 :  0.45226017\n",
      "17 32 :  0.54854304\n",
      "18 32 :  0.47834966\n",
      "19 32 :  0.39859354\n",
      "20 32 :  0.49495503\n",
      "21 32 :  0.47436753\n",
      "22 32 :  0.36736384\n",
      "23 32 :  0.500816\n",
      "24 32 :  0.47747177\n",
      "25 32 :  0.543942\n",
      "26 32 :  0.4103507\n",
      "27 32 :  0.5733178\n",
      "28 32 :  0.42641798\n",
      "29 32 :  0.5697387\n",
      "30 32 :  0.48681688\n",
      "31 32 :  0.49309477\n",
      "32 32 :  0.61562365\n",
      "train 1: {'f1': 0.3569131846433371}  f1\n",
      "train 1: {'accuracy': 0.41731507928691025} acc\n",
      "valid 1: 0.4647665023803711 loss\n",
      "valid 1: {'f1': 0.342960407890332}  f1\n",
      "valid 1: {'accuracy': 0.44682115270350564} acc\n",
      "1 32 :  0.46639588\n",
      "2 32 :  0.44591802\n",
      "3 32 :  0.42298487\n",
      "4 32 :  0.44300225\n",
      "5 32 :  0.480435\n",
      "6 32 :  0.50495094\n",
      "7 32 :  0.48883024\n",
      "8 32 :  0.5332014\n",
      "9 32 :  0.50953186\n",
      "10 32 :  0.4977365\n",
      "11 32 :  0.4616769\n",
      "12 32 :  0.49111882\n",
      "13 32 :  0.43696207\n",
      "14 32 :  0.42328295\n",
      "15 32 :  0.40086073\n",
      "16 32 :  0.45783368\n",
      "17 32 :  0.43977264\n",
      "18 32 :  0.49800885\n",
      "19 32 :  0.4059775\n",
      "20 32 :  0.503201\n",
      "21 32 :  0.43168226\n",
      "22 32 :  0.343699\n",
      "23 32 :  0.38263154\n",
      "24 32 :  0.44259802\n",
      "25 32 :  0.5177204\n",
      "26 32 :  0.3770528\n",
      "27 32 :  0.47340843\n",
      "28 32 :  0.3603339\n",
      "29 32 :  0.4087132\n",
      "30 32 :  0.44703174\n",
      "31 32 :  0.4124381\n",
      "32 32 :  0.39780882\n",
      "train 2: {'f1': 0.42296583752354844}  f1\n",
      "train 2: {'accuracy': 0.47289186263898453} acc\n",
      "valid 2: 0.4363285303115845 loss\n",
      "valid 2: {'f1': 0.42780423091501524}  f1\n",
      "valid 2: {'accuracy': 0.477124183006536} acc\n",
      "1 32 :  0.4153754\n",
      "2 32 :  0.37643248\n",
      "3 32 :  0.51644266\n",
      "4 32 :  0.4481722\n",
      "5 32 :  0.50615644\n",
      "6 32 :  0.48220786\n",
      "7 32 :  0.43623793\n",
      "8 32 :  0.44059536\n",
      "9 32 :  0.36341012\n",
      "10 32 :  0.41662624\n",
      "11 32 :  0.5138526\n",
      "12 32 :  0.42291823\n",
      "13 32 :  0.4638662\n",
      "14 32 :  0.43538123\n",
      "15 32 :  0.3632223\n",
      "16 32 :  0.34468275\n",
      "17 32 :  0.5472019\n",
      "18 32 :  0.36161458\n",
      "19 32 :  0.41794968\n",
      "20 32 :  0.37514663\n",
      "21 32 :  0.4776473\n",
      "22 32 :  0.48325542\n",
      "23 32 :  0.3234451\n",
      "24 32 :  0.4577434\n",
      "25 32 :  0.45768243\n",
      "26 32 :  0.3751458\n",
      "27 32 :  0.42374542\n",
      "28 32 :  0.34192732\n",
      "29 32 :  0.4092284\n",
      "30 32 :  0.3759023\n",
      "31 32 :  0.49415144\n",
      "32 32 :  0.26913464\n",
      "train 3: {'f1': 0.46437544813202064}  f1\n",
      "train 3: {'accuracy': 0.5059992132179386} acc\n",
      "valid 3: 0.4333067834377289 loss\n",
      "valid 3: {'f1': 0.4414513026996776}  f1\n",
      "valid 3: {'accuracy': 0.4976232917409388} acc\n",
      "1 32 :  0.3821214\n",
      "2 32 :  0.37575686\n",
      "3 32 :  0.42445818\n",
      "4 32 :  0.42082098\n",
      "5 32 :  0.36581072\n",
      "6 32 :  0.3626016\n",
      "7 32 :  0.36928248\n",
      "8 32 :  0.45771277\n",
      "9 32 :  0.3686487\n",
      "10 32 :  0.42093176\n",
      "11 32 :  0.46364167\n",
      "12 32 :  0.5021201\n",
      "13 32 :  0.34646687\n",
      "14 32 :  0.37564823\n",
      "15 32 :  0.39705557\n",
      "16 32 :  0.47282934\n",
      "17 32 :  0.45116365\n",
      "18 32 :  0.36508662\n",
      "19 32 :  0.46421474\n",
      "20 32 :  0.38346702\n",
      "21 32 :  0.41023377\n",
      "22 32 :  0.4540411\n",
      "23 32 :  0.36751476\n",
      "24 32 :  0.36230868\n",
      "25 32 :  0.3482999\n",
      "26 32 :  0.4551064\n",
      "27 32 :  0.40928924\n",
      "28 32 :  0.51991904\n",
      "29 32 :  0.51575893\n",
      "30 32 :  0.36321706\n",
      "31 32 :  0.43751016\n",
      "32 32 :  0.31670305\n",
      "train 4: {'f1': 0.49482751239517025}  f1\n",
      "train 4: {'accuracy': 0.531810124089029} acc\n",
      "valid 4: 0.44038617610931396 loss\n",
      "valid 4: {'f1': 0.4253846766974358}  f1\n",
      "valid 4: {'accuracy': 0.4423648247177659} acc\n",
      "1 32 :  0.3850325\n",
      "2 32 :  0.3871311\n",
      "3 32 :  0.40984243\n",
      "4 32 :  0.38731363\n",
      "5 32 :  0.44621676\n",
      "6 32 :  0.35532147\n",
      "7 32 :  0.43999326\n",
      "8 32 :  0.3949166\n",
      "9 32 :  0.4286612\n",
      "10 32 :  0.4080854\n",
      "11 32 :  0.41711807\n",
      "12 32 :  0.3426772\n",
      "13 32 :  0.47199732\n",
      "14 32 :  0.48674613\n",
      "15 32 :  0.39853746\n",
      "16 32 :  0.3726982\n",
      "17 32 :  0.5146184\n",
      "18 32 :  0.36785063\n",
      "19 32 :  0.42717302\n",
      "20 32 :  0.47880214\n",
      "21 32 :  0.40562567\n",
      "22 32 :  0.4557542\n",
      "23 32 :  0.31264016\n",
      "24 32 :  0.33955207\n",
      "25 32 :  0.3560723\n",
      "26 32 :  0.40581504\n",
      "27 32 :  0.3717744\n",
      "28 32 :  0.32499096\n",
      "29 32 :  0.40932432\n",
      "30 32 :  0.38511768\n",
      "31 32 :  0.38731915\n",
      "32 32 :  0.40080562\n",
      "train 5: {'f1': 0.5059168417333898}  f1\n",
      "train 5: {'accuracy': 0.5378720895962276} acc\n",
      "valid 5: 0.3991219699382782 loss\n",
      "valid 5: {'f1': 0.49200020532207694}  f1\n",
      "valid 5: {'accuracy': 0.5273321449792038} acc\n",
      "1 32 :  0.39536107\n",
      "2 32 :  0.4911958\n",
      "3 32 :  0.33571836\n",
      "4 32 :  0.34501463\n",
      "5 32 :  0.32198814\n",
      "6 32 :  0.3462469\n",
      "7 32 :  0.397088\n",
      "8 32 :  0.34786308\n",
      "9 32 :  0.42005113\n",
      "10 32 :  0.418666\n",
      "11 32 :  0.36945045\n",
      "12 32 :  0.33511057\n",
      "13 32 :  0.339031\n",
      "14 32 :  0.46676204\n",
      "15 32 :  0.39727512\n",
      "16 32 :  0.35533485\n",
      "17 32 :  0.42460158\n",
      "18 32 :  0.376722\n",
      "19 32 :  0.38067785\n",
      "20 32 :  0.46141958\n",
      "21 32 :  0.44363552\n",
      "22 32 :  0.3649133\n",
      "23 32 :  0.36444983\n",
      "24 32 :  0.3918934\n",
      "25 32 :  0.41117948\n",
      "26 32 :  0.33496344\n",
      "27 32 :  0.33448914\n",
      "28 32 :  0.4926533\n",
      "29 32 :  0.31294686\n",
      "30 32 :  0.4747778\n",
      "31 32 :  0.33546865\n",
      "32 32 :  0.35606173\n",
      "train 6: {'f1': 0.5273460513867113}  f1\n",
      "train 6: {'accuracy': 0.5595214747989802} acc\n",
      "valid 6: 0.4092673063278198 loss\n",
      "valid 6: {'f1': 0.48855252490674195}  f1\n",
      "valid 6: {'accuracy': 0.5133689839572193} acc\n",
      "1 32 :  0.3491084\n",
      "2 32 :  0.3786169\n",
      "3 32 :  0.36189115\n",
      "4 32 :  0.42562816\n",
      "5 32 :  0.34571195\n",
      "6 32 :  0.3764217\n",
      "7 32 :  0.4689531\n",
      "8 32 :  0.39843827\n",
      "9 32 :  0.42839915\n",
      "10 32 :  0.4403629\n",
      "11 32 :  0.43708354\n",
      "12 32 :  0.4057185\n",
      "13 32 :  0.36217323\n",
      "14 32 :  0.34573942\n",
      "15 32 :  0.42548752\n",
      "16 32 :  0.35637805\n",
      "17 32 :  0.349028\n",
      "18 32 :  0.37592962\n",
      "19 32 :  0.34654295\n",
      "20 32 :  0.29684407\n",
      "21 32 :  0.43113002\n",
      "22 32 :  0.42553478\n",
      "23 32 :  0.52539307\n",
      "24 32 :  0.3722453\n",
      "25 32 :  0.3651836\n",
      "26 32 :  0.41416916\n",
      "27 32 :  0.40196854\n",
      "28 32 :  0.36201268\n",
      "29 32 :  0.31466597\n",
      "30 32 :  0.31684172\n",
      "31 32 :  0.3546086\n",
      "32 32 :  0.34930548\n",
      "train 7: {'f1': 0.5311843651488701}  f1\n",
      "train 7: {'accuracy': 0.5595824305692338} acc\n",
      "valid 7: 0.41263848543167114 loss\n",
      "valid 7: {'f1': 0.47614059748196785}  f1\n",
      "valid 7: {'accuracy': 0.5335710041592394} acc\n",
      "1 32 :  0.39604148\n",
      "2 32 :  0.37991375\n",
      "3 32 :  0.4437079\n",
      "4 32 :  0.29517868\n",
      "5 32 :  0.32292402\n",
      "6 32 :  0.41505912\n",
      "7 32 :  0.38913533\n",
      "8 32 :  0.35531318\n",
      "9 32 :  0.35913786\n",
      "10 32 :  0.36386955\n",
      "11 32 :  0.3072448\n",
      "12 32 :  0.33070287\n",
      "13 32 :  0.3682009\n",
      "14 32 :  0.35062283\n",
      "15 32 :  0.45000008\n",
      "16 32 :  0.27821437\n",
      "17 32 :  0.33581573\n",
      "18 32 :  0.4663687\n",
      "19 32 :  0.38111427\n",
      "20 32 :  0.3524833\n",
      "21 32 :  0.39827526\n",
      "22 32 :  0.3780165\n",
      "23 32 :  0.45314196\n",
      "24 32 :  0.4098197\n",
      "25 32 :  0.39501432\n",
      "26 32 :  0.42697933\n",
      "27 32 :  0.4183225\n",
      "28 32 :  0.43925726\n",
      "29 32 :  0.32501546\n",
      "30 32 :  0.3549867\n",
      "31 32 :  0.3335023\n",
      "32 32 :  0.41896898\n",
      "train 8: {'f1': 0.5445271793228172}  f1\n",
      "train 8: {'accuracy': 0.5729320350152454} acc\n",
      "valid 8: 0.42369985580444336 loss\n",
      "valid 8: {'f1': 0.4390709062688005}  f1\n",
      "valid 8: {'accuracy': 0.5121806298276886} acc\n",
      "1 32 :  0.41773677\n",
      "2 32 :  0.4411458\n",
      "3 32 :  0.37734357\n",
      "4 32 :  0.357326\n",
      "5 32 :  0.33298048\n",
      "6 32 :  0.38193196\n",
      "7 32 :  0.3165154\n",
      "8 32 :  0.39693412\n",
      "9 32 :  0.29024047\n",
      "10 32 :  0.37951684\n",
      "11 32 :  0.3600444\n",
      "12 32 :  0.39395508\n",
      "13 32 :  0.27894002\n",
      "14 32 :  0.4433889\n",
      "15 32 :  0.48349953\n",
      "16 32 :  0.39548507\n",
      "17 32 :  0.3473267\n",
      "18 32 :  0.31915694\n",
      "19 32 :  0.30998775\n",
      "20 32 :  0.37816572\n",
      "21 32 :  0.41090178\n",
      "22 32 :  0.35877508\n",
      "23 32 :  0.32401136\n",
      "24 32 :  0.32542425\n",
      "25 32 :  0.37437326\n",
      "26 32 :  0.34547693\n",
      "27 32 :  0.3752893\n",
      "28 32 :  0.37190732\n",
      "29 32 :  0.33275163\n",
      "30 32 :  0.40190414\n",
      "31 32 :  0.44659203\n",
      "32 32 :  0.39895418\n",
      "train 9: {'f1': 0.5487570985556898}  f1\n",
      "train 9: {'accuracy': 0.5769079850892682} acc\n",
      "valid 9: 0.4019310772418976 loss\n",
      "valid 9: {'f1': 0.4972724897547799}  f1\n",
      "valid 9: {'accuracy': 0.5407011289364231} acc\n",
      "1 32 :  0.40945083\n",
      "2 32 :  0.4240703\n",
      "3 32 :  0.31534064\n",
      "4 32 :  0.34584132\n",
      "5 32 :  0.31995788\n",
      "6 32 :  0.46499786\n",
      "7 32 :  0.3805286\n",
      "8 32 :  0.36645404\n",
      "9 32 :  0.3755818\n",
      "10 32 :  0.40144637\n",
      "11 32 :  0.36640424\n",
      "12 32 :  0.34742337\n",
      "13 32 :  0.33670527\n",
      "14 32 :  0.28943124\n",
      "15 32 :  0.41199043\n",
      "16 32 :  0.30976012\n",
      "17 32 :  0.3734518\n",
      "18 32 :  0.3396792\n",
      "19 32 :  0.3976465\n",
      "20 32 :  0.31352597\n",
      "21 32 :  0.37601122\n",
      "22 32 :  0.35197416\n",
      "23 32 :  0.36954257\n",
      "24 32 :  0.46090335\n",
      "25 32 :  0.38944724\n",
      "26 32 :  0.3594717\n",
      "27 32 :  0.32931316\n",
      "28 32 :  0.3286542\n",
      "29 32 :  0.3914893\n",
      "30 32 :  0.29064175\n",
      "31 32 :  0.3394423\n",
      "32 32 :  0.39700016\n",
      "train 10: {'f1': 0.5553062694872597}  f1\n",
      "train 10: {'accuracy': 0.5835220001968697} acc\n",
      "valid 10: 0.3971203863620758 loss\n",
      "valid 10: {'f1': 0.4868737694869578}  f1\n",
      "valid 10: {'accuracy': 0.533868092691622} acc\n",
      "1 32 :  0.29933375\n",
      "2 32 :  0.44616568\n",
      "3 32 :  0.3773806\n",
      "4 32 :  0.37949046\n",
      "5 32 :  0.38252646\n",
      "6 32 :  0.32915655\n",
      "7 32 :  0.39218453\n",
      "8 32 :  0.35006207\n",
      "9 32 :  0.30405357\n",
      "10 32 :  0.32145092\n",
      "11 32 :  0.35639274\n",
      "12 32 :  0.3661432\n",
      "13 32 :  0.29694083\n",
      "14 32 :  0.36186346\n",
      "15 32 :  0.355803\n",
      "16 32 :  0.3936633\n",
      "17 32 :  0.28726184\n",
      "18 32 :  0.3339342\n",
      "19 32 :  0.3661467\n",
      "20 32 :  0.3426098\n",
      "21 32 :  0.3668603\n",
      "22 32 :  0.34648845\n",
      "23 32 :  0.29692298\n",
      "24 32 :  0.40530595\n",
      "25 32 :  0.3696462\n",
      "26 32 :  0.42687196\n",
      "27 32 :  0.29718226\n",
      "28 32 :  0.3676478\n",
      "29 32 :  0.39225656\n",
      "30 32 :  0.29271144\n",
      "31 32 :  0.38358793\n",
      "32 32 :  0.31192228\n",
      "train 11: {'f1': 0.572226262680641}  f1\n",
      "train 11: {'accuracy': 0.5957697983275947} acc\n",
      "valid 11: 0.39836788177490234 loss\n",
      "valid 11: {'f1': 0.4926719935070032}  f1\n",
      "valid 11: {'accuracy': 0.511883541295306} acc\n",
      "1 32 :  0.33259487\n",
      "2 32 :  0.34174138\n",
      "3 32 :  0.35194653\n",
      "4 32 :  0.30510464\n",
      "5 32 :  0.34315628\n",
      "6 32 :  0.3528119\n",
      "7 32 :  0.3383394\n",
      "8 32 :  0.36305967\n",
      "9 32 :  0.32368425\n",
      "10 32 :  0.37283963\n",
      "11 32 :  0.38661116\n",
      "12 32 :  0.31559825\n",
      "13 32 :  0.37008008\n",
      "14 32 :  0.32320502\n",
      "15 32 :  0.29883167\n",
      "16 32 :  0.34102818\n",
      "17 32 :  0.28782627\n",
      "18 32 :  0.38524798\n",
      "19 32 :  0.31039396\n",
      "20 32 :  0.3445662\n",
      "21 32 :  0.46979842\n",
      "22 32 :  0.36886403\n",
      "23 32 :  0.35018396\n",
      "24 32 :  0.43690452\n",
      "25 32 :  0.35929278\n",
      "26 32 :  0.32308048\n",
      "27 32 :  0.34778097\n",
      "28 32 :  0.36823028\n",
      "29 32 :  0.40079793\n",
      "30 32 :  0.3584796\n",
      "31 32 :  0.37367508\n",
      "32 32 :  0.32850528\n",
      "train 12: {'f1': 0.5741152315222193}  f1\n",
      "train 12: {'accuracy': 0.596458435809149} acc\n",
      "valid 12: 0.40842390060424805 loss\n",
      "valid 12: {'f1': 0.478278967144542}  f1\n",
      "valid 12: {'accuracy': 0.5344622697563874} acc\n",
      "1 32 :  0.3609039\n",
      "2 32 :  0.34593803\n",
      "3 32 :  0.34877488\n",
      "4 32 :  0.35295984\n",
      "5 32 :  0.3068441\n",
      "6 32 :  0.36053535\n",
      "7 32 :  0.29048678\n",
      "8 32 :  0.2441519\n",
      "9 32 :  0.3201567\n",
      "10 32 :  0.3648547\n",
      "11 32 :  0.36559606\n",
      "12 32 :  0.32690957\n",
      "13 32 :  0.34325683\n",
      "14 32 :  0.34110188\n",
      "15 32 :  0.34217143\n",
      "16 32 :  0.39453802\n",
      "17 32 :  0.40197375\n",
      "18 32 :  0.3162565\n",
      "19 32 :  0.45277733\n",
      "20 32 :  0.34865367\n",
      "21 32 :  0.33875358\n",
      "22 32 :  0.3859317\n",
      "23 32 :  0.292207\n",
      "24 32 :  0.33062914\n",
      "25 32 :  0.36001393\n",
      "26 32 :  0.3242117\n",
      "27 32 :  0.35899404\n",
      "28 32 :  0.31639335\n",
      "29 32 :  0.40965188\n",
      "30 32 :  0.35493082\n",
      "31 32 :  0.34649155\n",
      "32 32 :  0.41982558\n",
      "train 13: {'f1': 0.5727566395989878}  f1\n",
      "train 13: {'accuracy': 0.5979948889325732} acc\n",
      "valid 13: 0.40186846256256104 loss\n",
      "valid 13: {'f1': 0.5002923688029215}  f1\n",
      "valid 13: {'accuracy': 0.5445632798573975} acc\n",
      "1 32 :  0.35761443\n",
      "2 32 :  0.3282558\n",
      "3 32 :  0.38857743\n",
      "4 32 :  0.35183814\n",
      "5 32 :  0.27584922\n",
      "6 32 :  0.2877455\n",
      "7 32 :  0.39514115\n",
      "8 32 :  0.3055589\n",
      "9 32 :  0.35528588\n",
      "10 32 :  0.44711158\n",
      "11 32 :  0.3205496\n",
      "12 32 :  0.34342015\n",
      "13 32 :  0.305091\n",
      "14 32 :  0.33838707\n",
      "15 32 :  0.3735028\n",
      "16 32 :  0.3903614\n",
      "17 32 :  0.3306222\n",
      "18 32 :  0.38195106\n",
      "19 32 :  0.28742033\n",
      "20 32 :  0.3326649\n",
      "21 32 :  0.37485054\n",
      "22 32 :  0.37707296\n",
      "23 32 :  0.36004323\n",
      "24 32 :  0.40078753\n",
      "25 32 :  0.31858066\n",
      "26 32 :  0.3297438\n",
      "27 32 :  0.30302656\n",
      "28 32 :  0.29797125\n",
      "29 32 :  0.3471656\n",
      "30 32 :  0.37007105\n",
      "31 32 :  0.3449184\n",
      "32 32 :  0.3373904\n",
      "train 14: {'f1': 0.5846524740294458}  f1\n",
      "train 14: {'accuracy': 0.6067603419475287} acc\n",
      "valid 14: 0.40599745512008667 loss\n",
      "valid 14: {'f1': 0.511631569451762}  f1\n",
      "valid 14: {'accuracy': 0.5412953060011884} acc\n",
      "1 32 :  0.36984658\n",
      "2 32 :  0.35974404\n",
      "3 32 :  0.30478692\n",
      "4 32 :  0.30121943\n",
      "5 32 :  0.37203956\n",
      "6 32 :  0.34261835\n",
      "7 32 :  0.30143824\n",
      "8 32 :  0.3227604\n",
      "9 32 :  0.3475696\n",
      "10 32 :  0.32635593\n",
      "11 32 :  0.29280388\n",
      "12 32 :  0.33878666\n",
      "13 32 :  0.38303503\n",
      "14 32 :  0.34035006\n",
      "15 32 :  0.255235\n",
      "16 32 :  0.35762793\n",
      "17 32 :  0.32168406\n",
      "18 32 :  0.3877059\n",
      "19 32 :  0.33345506\n",
      "20 32 :  0.32268786\n",
      "21 32 :  0.26375017\n",
      "22 32 :  0.3103681\n",
      "23 32 :  0.31987706\n",
      "24 32 :  0.3864559\n",
      "25 32 :  0.3337127\n",
      "26 32 :  0.32766914\n",
      "27 32 :  0.3593508\n",
      "28 32 :  0.29835987\n",
      "29 32 :  0.31984058\n",
      "30 32 :  0.3575627\n",
      "31 32 :  0.2930382\n",
      "32 32 :  0.3955815\n",
      "train 15: {'f1': 0.5994486559122554}  f1\n",
      "train 15: {'accuracy': 0.6210050152424034} acc\n",
      "valid 15: 0.39753201603889465 loss\n",
      "valid 15: {'f1': 0.5144816729673666}  f1\n",
      "valid 15: {'accuracy': 0.5433749257278669} acc\n",
      "1 32 :  0.4158309\n",
      "2 32 :  0.30947512\n",
      "3 32 :  0.39894179\n",
      "4 32 :  0.29232696\n",
      "5 32 :  0.33944273\n",
      "6 32 :  0.34762314\n",
      "7 32 :  0.32097325\n",
      "8 32 :  0.34492305\n",
      "9 32 :  0.29860744\n",
      "10 32 :  0.41253722\n",
      "11 32 :  0.37767857\n",
      "12 32 :  0.3486491\n",
      "13 32 :  0.36387745\n",
      "14 32 :  0.32216242\n",
      "15 32 :  0.33757663\n",
      "16 32 :  0.3146522\n",
      "17 32 :  0.2959488\n",
      "18 32 :  0.3071645\n",
      "19 32 :  0.28851116\n",
      "20 32 :  0.34991923\n",
      "21 32 :  0.2648959\n",
      "22 32 :  0.37416464\n",
      "23 32 :  0.32893613\n",
      "24 32 :  0.30090818\n",
      "25 32 :  0.3284498\n",
      "26 32 :  0.2674448\n",
      "27 32 :  0.31494737\n",
      "28 32 :  0.3001806\n",
      "29 32 :  0.24668877\n",
      "30 32 :  0.34538943\n",
      "31 32 :  0.36600652\n",
      "32 32 :  0.37057012\n",
      "train 16: {'f1': 0.5989346135741342}  f1\n",
      "train 16: {'accuracy': 0.6191689533516268} acc\n",
      "valid 16: 0.4094565510749817 loss\n",
      "valid 16: {'f1': 0.49173028226170495}  f1\n",
      "valid 16: {'accuracy': 0.5092097445038621} acc\n",
      "1 32 :  0.35697338\n",
      "2 32 :  0.26792476\n",
      "3 32 :  0.2762538\n",
      "4 32 :  0.3029617\n",
      "5 32 :  0.34458968\n",
      "6 32 :  0.34176022\n",
      "7 32 :  0.31223008\n",
      "8 32 :  0.40514544\n",
      "9 32 :  0.3538315\n",
      "10 32 :  0.33926278\n",
      "11 32 :  0.26855874\n",
      "12 32 :  0.30075303\n",
      "13 32 :  0.266297\n",
      "14 32 :  0.37636244\n",
      "15 32 :  0.346975\n",
      "16 32 :  0.31625623\n",
      "17 32 :  0.2803395\n",
      "18 32 :  0.29818243\n",
      "19 32 :  0.38949817\n",
      "20 32 :  0.26596394\n",
      "21 32 :  0.30793118\n",
      "22 32 :  0.39570418\n",
      "23 32 :  0.32749373\n",
      "24 32 :  0.30225876\n",
      "25 32 :  0.3355845\n",
      "26 32 :  0.29787427\n",
      "27 32 :  0.2827566\n",
      "28 32 :  0.31061497\n",
      "29 32 :  0.31368986\n",
      "30 32 :  0.36787727\n",
      "31 32 :  0.3759566\n",
      "32 32 :  0.3055382\n",
      "train 17: {'f1': 0.6152396958530114}  f1\n",
      "train 17: {'accuracy': 0.6341056351855487} acc\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    for i, X in enumerate(dataloader['train']):\n",
    "        # Ignore padded entries\n",
    "        input_mask = X['conv_attn_mask'].sum(axis=1).astype(jnp.int32)\n",
    "\n",
    "        # Forward and backward pass\n",
    "        loss_train, logits, key, trainer.state = trainer.train_step(key, trainer.state, X)\n",
    "\n",
    "        # Track training loss\n",
    "        print(i + 1, len(dataloader['train']), ': ', loss_train)\n",
    "\n",
    "        # Track F1\n",
    "        pred = take_until_index(logits, input_mask).argmax(axis=1)\n",
    "        real = take_until_index(X['emotion_labels'], input_mask)\n",
    "        f1_score.add_batch(predictions=pred, references=real)\n",
    "        accuracy.add_batch(predictions=pred, references=real)\n",
    "    print('train {}: {}  f1'.format(epoch, f1_score.compute(average='weighted')))\n",
    "    print('train {}: {} acc'.format(epoch, accuracy.compute()))\n",
    "\n",
    "    losses = []\n",
    "    for i, X in enumerate(dataloader['valid']):\n",
    "        # Ignore padded entries\n",
    "        input_mask = X['conv_attn_mask'].sum(axis=1).astype(jnp.int32)\n",
    "\n",
    "        # Forward pass\n",
    "        loss_valid, logits, key, _ = trainer.eval_step(key, trainer.state, X)\n",
    "        losses.append(loss_valid)\n",
    "\n",
    "        # Track F1\n",
    "        pred = take_until_index(logits, input_mask).argmax(axis=1)\n",
    "        real = take_until_index(X['emotion_labels'], input_mask)\n",
    "        f1_score.add_batch(predictions=pred, references=real)\n",
    "        accuracy.add_batch(predictions=pred, references=real)\n",
    "    print('valid {}: {} loss'.format(epoch, np.array(losses).mean()))\n",
    "    print('valid {}: {}  f1'.format(epoch, f1_score.compute(average='weighted')))\n",
    "    print('valid {}: {} acc'.format(epoch, accuracy.compute()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotion-analysis-adVGJZXD-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
