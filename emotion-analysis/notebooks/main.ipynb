{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internal Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX Backend:  gpu\n",
      "JAX Version:  0.4.23\n",
      "Python:  3.11.0 (main, Oct  4 2023, 22:00:02) [GCC 13.2.1 20230801]\n",
      "System:  posix.uname_result(sysname='Linux', nodename='archlinux', release='6.7.0-arch3-1', version='#1 SMP PREEMPT_DYNAMIC Sat, 13 Jan 2024 14:37:14 +0000', machine='x86_64')\n"
     ]
    }
   ],
   "source": [
    "# Find \".env\" file and add the package to $PATH\n",
    "import os, sys\n",
    "import typing as t\n",
    "from typing import Dict, TypeAlias, Any\n",
    "from dotenv import find_dotenv\n",
    "sys.path.append(os.path.dirname(find_dotenv()))\n",
    "\n",
    "# Use local package for modularity\n",
    "import emotion_analysis as ea\n",
    "from emotion_analysis import config\n",
    "from emotion_analysis.data.dataset import ECACDataset\n",
    "from emotion_analysis.data.loader import DefaultDataLoader\n",
    "from emotion_analysis.data.types import TrainSplit, DataSplit, SubTask\n",
    "from emotion_analysis.data.transform import DataTokenize, DataTransform, DataCollator\n",
    "from emotion_analysis.model.emotion_cause_text import load_text_model\n",
    "from emotion_analysis.model.emotion_cause_text import EmotionCauseTextModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "External Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrm\n",
    "from jax import Array\n",
    "import jax.tree_util as tree_util\n",
    "from jax.tree_util import tree_structure\n",
    "from jax.typing import ArrayLike, DTypeLike\n",
    "import flax\n",
    "import flax.linen as nn\n",
    "import numpy as np\n",
    "import optax as opt\n",
    "import mlflow as mlf\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessors\n",
    "text_encoder_pretrained = load_text_model(config.model_repo)\n",
    "tokenizer = text_encoder_pretrained.tokenizer\n",
    "tokenize = DataTokenize( tokenizer,  max_seq_len=config.max_uttr_len)\n",
    "transform = DataTransform(tokenize, max_conv_len=config.max_conv_len)\n",
    "collator = DataCollator(transform)\n",
    "\n",
    "# Load data subsets\n",
    "dataset: Dict[DataSplit, ECACDataset] = ECACDataset.read_data(config.data_dir, config.subtask)\n",
    "ds_train, ds_valid, ds_test = *random_split(dataset['train'], [0.75, 0.25]), dataset['test']\n",
    "num_classes: int = dataset['train'].num_emotions\n",
    "\n",
    "# Train: drop_last=True to avoid JAX graph recompilation\n",
    "dataloader: t.Dict[TrainSplit, DataLoader[t.Dict[str, Array]]] = {\n",
    "    'train': DefaultDataLoader(ds_train,  shuffle=True, collate_fn=collator, drop_last=True),\n",
    "    'valid': DefaultDataLoader(ds_train, shuffle=False, collate_fn=collator),\n",
    "    'test' : DefaultDataLoader( ds_test, shuffle=False, collate_fn=collator),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a PR key for init\n",
    "key = jrm.key(config.seed)\n",
    "key, init_key = jrm.split(key, 2)\n",
    "\n",
    "# Generate fake data to \"imitate\" a batch\n",
    "fake_input_ids = jnp.zeros((config.batch_size * config.max_conv_len, config.max_uttr_len))\n",
    "fake_attn_mask = jnp.zeros_like(fake_input_ids)\n",
    "fake_batch: Any = dict(input_ids=fake_input_ids, attention_mask=fake_attn_mask)\n",
    "\n",
    "# Initialize the model with random params\n",
    "ec_model = EmotionCauseTextModel(text_encoder=text_encoder_pretrained.module, num_classes=num_classes)\n",
    "vars = ec_model.init(init_key, **fake_batch)\n",
    "params = vars['params']\n",
    "\n",
    "# Transfer the pretrained weights \n",
    "params['text_encoder'] = text_encoder_pretrained.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train only the classifier for now...\n",
    "should_freeze = lambda p, _: 'frozen' if 'text_encoder' in p else 'trainable'\n",
    "param_labels = flax.traverse_util.path_aware_map(should_freeze, params)\n",
    "tx = opt.multi_transform({ 'trainable': opt.adamw(2e-4), 'frozen': opt.set_to_zero() }, param_labels)\n",
    "opt_state = tx.init(params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotion-analysis-adVGJZXD-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
