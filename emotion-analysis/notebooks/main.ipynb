{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internal Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX Backend:  gpu\n",
      "JAX Version:  0.4.23\n",
      "Python:  3.11.0 (main, Oct  4 2023, 22:00:02) [GCC 13.2.1 20230801]\n",
      "System:  posix.uname_result(sysname='Linux', nodename='archlinux', release='6.7.0-arch3-1', version='#1 SMP PREEMPT_DYNAMIC Sat, 13 Jan 2024 14:37:14 +0000', machine='x86_64')\n"
     ]
    }
   ],
   "source": [
    "# Find \".env\" file and add the package to $PATH\n",
    "import os, sys\n",
    "import typing as t\n",
    "from typing import Dict\n",
    "from dotenv import find_dotenv\n",
    "sys.path.append(os.path.dirname(find_dotenv()))\n",
    "\n",
    "# Use local package for modularity\n",
    "from emotion_analysis import config\n",
    "from emotion_analysis.utils.weight import INSWeight\n",
    "from emotion_analysis.model.pretrained import load_text_model\n",
    "from emotion_analysis.model.trainer import TrainerModule\n",
    "from emotion_analysis.data.dataset import ECACDataset\n",
    "from emotion_analysis.data.loader import DefaultDataLoader\n",
    "from emotion_analysis.data.types import EmotionCauseEncoding\n",
    "from emotion_analysis.data.types import TrainSplit, DataSplit\n",
    "from emotion_analysis.data.transform import TokenizeTransform, EncodeTransform, CollateTransform, Transform, WeightTransform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "External Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax\n",
    "import flax.linen as nn\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrm\n",
    "import jax.tree_util as tree_util\n",
    "import mlflow as mlf\n",
    "import seaborn as sea\n",
    "import numpy as np\n",
    "import optax as opt\n",
    "from jax import Array\n",
    "from jax.tree_util import tree_structure\n",
    "from jax.typing import ArrayLike, DTypeLike\n",
    "from numpy import ndarray\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data subsets in-memory\n",
    "dataset: Dict[DataSplit, ECACDataset] = ECACDataset.read_data(config.data_dir, config.subtask)\n",
    "# ds_train, ds_valid, ds_test = *random_split(dataset['train'], [0.75, 0.25]), dataset['test']\n",
    "\n",
    "# Extract relevant statistics\n",
    "num_classes: int = dataset['train'].num_emotions\n",
    "emotion_labels = dataset['train'].emotion_labels\n",
    "emotion_weights = INSWeight(num_classes, emotion_labels)\n",
    "\n",
    "# Load pretrained model\n",
    "text_encoder_pretrained = load_text_model(config.model_repo, config.cache_dir)\n",
    "tokenizer = text_encoder_pretrained.tokenizer\n",
    "\n",
    "# Compose data transformations\n",
    "tokenize = TokenizeTransform(tokenizer, max_seq_len=config.max_uttr_len)\n",
    "encode = EncodeTransform(tokenize, max_conv_len=config.max_conv_len)\n",
    "weight = WeightTransform(emotion_weights)\n",
    "collator = CollateTransform(Transform.chain(encode, weight))\n",
    "\n",
    "# Train: drop_last=True to avoid JAX graph recompilation\n",
    "dataloader: t.Dict[TrainSplit, DataLoader[EmotionCauseEncoding]] = {\n",
    "    'train': DefaultDataLoader(Subset(dataset['train'], [0, 1]), shuffle=False, collate_fn=collator, drop_last=True),\n",
    "    'valid': DefaultDataLoader(Subset(dataset['train'], [0, 1]), shuffle=False, collate_fn=collator),\n",
    "    # 'test' : DefaultDataLoader( ds_test, shuffle=False, collate_fn=collator),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jrm.PRNGKey(config.seed)\n",
    "key, trainer_key = jrm.split(key, 2)\n",
    "trainer = TrainerModule(\n",
    "    key=trainer_key,\n",
    "    finetune=config.finetune,\n",
    "    batch_size=config.batch_size,\n",
    "    max_conv_len=config.max_conv_len,\n",
    "    max_uttr_len=config.max_uttr_len,\n",
    "    text_model_repo=config.model_repo,\n",
    "    learning_rate=config.learning_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[training]:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[train][epoch: 0]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 1]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 2]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 3]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 4]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 5]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 6]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 7]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 8]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 9]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 10]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 11]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 12]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 13]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 14]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "[train][epoch: 15]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 16]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 17]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 18]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 19]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 20]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "[train][epoch: 21]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 22]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "[train][epoch: 23]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 24]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 25]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "[train][epoch: 26]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 27]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 28]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 29]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 30]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 31]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 32]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 33]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 34]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "[train][epoch: 35]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 36]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "[train][epoch: 37]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 38]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 39]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 40]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 41]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 42]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 43]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 44]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[eval]: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "[train][epoch: 45]:   0%|          | 0/1 [00:00<?, ?it/s]it]\n",
      "[training]:  45%|████▌     | 45/100 [01:36<01:57,  2.13s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/git/ub-g21-irtm/emotion-analysis/emotion_analysis/model/trainer.py:330\u001b[0m, in \u001b[0;36mTrainerModule.train\u001b[0;34m(self, train_dataloader, valid_dataloader, tags, num_epochs)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;66;03m# Perform train & valid at each step\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m trange(num_epochs, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[training]\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 330\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_epoch(epoch, valid_dataloader)\n",
      "File \u001b[0;32m~/Projects/git/ub-g21-irtm/emotion-analysis/emotion_analysis/model/trainer.py:273\u001b[0m, in \u001b[0;36mTrainerModule.train_epoch\u001b[0;34m(self, epoch, dataloader)\u001b[0m\n\u001b[1;32m    271\u001b[0m     pred \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memotion\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m][conv_mask, :]\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    272\u001b[0m     refs \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memotion_labels\u001b[39m\u001b[38;5;124m'\u001b[39m][conv_mask]\n\u001b[0;32m--> 273\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_f1_emotion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreferences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_metric(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss\u001b[38;5;241m.\u001b[39mcompute(), step\u001b[38;5;241m=\u001b[39mepoch)\n\u001b[1;32m    275\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_metric(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss_span\u001b[39m\u001b[38;5;124m'\u001b[39m, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss_span\u001b[38;5;241m.\u001b[39mcompute(), step\u001b[38;5;241m=\u001b[39mepoch)\n",
      "File \u001b[0;32m~/Projects/git/ub-g21-irtm/emotion-analysis/emotion_analysis/model/metrics.py:56\u001b[0m, in \u001b[0;36mF1Metric.update\u001b[0;34m(self, predictions, references)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, predictions: Array, references: Array) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf1_score\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreferences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreferences\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/emotion-analysis-adVGJZXD-py3.11/lib/python3.11/site-packages/evaluate/module.py:510\u001b[0m, in \u001b[0;36mEvaluationModule.add_batch\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselected_feature_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_infer_feature_from_batch(batch)\n\u001b[0;32m--> 510\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, column \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/emotion-analysis-adVGJZXD-py3.11/lib/python3.11/site-packages/evaluate/module.py:644\u001b[0m, in \u001b[0;36mEvaluationModule._init_writer\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;66;03m# Get cache file name and lock it\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_file_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilelock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 644\u001b[0m     cache_file_name, filelock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_cache_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# get ready\u001b[39;00m\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_file_name \u001b[38;5;241m=\u001b[39m cache_file_name\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilelock \u001b[38;5;241m=\u001b[39m filelock\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/emotion-analysis-adVGJZXD-py3.11/lib/python3.11/site-packages/evaluate/module.py:279\u001b[0m, in \u001b[0;36mEvaluationModule._create_cache_file\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m filelock \u001b[38;5;241m=\u001b[39m FileLock(file_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.lock\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[43mfilelock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Timeout:\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;66;03m# If we have reached the max number of attempts or we are not allow to find a free name (distributed setup)\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;66;03m# We raise an error\u001b[39;00m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_process \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/emotion-analysis-adVGJZXD-py3.11/lib/python3.11/site-packages/filelock/_api.py:267\u001b[0m, in \u001b[0;36mBaseFileLock.acquire\u001b[0;34m(self, timeout, poll_interval, poll_intervall, blocking)\u001b[0m\n\u001b[1;32m    265\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLock \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m not acquired on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, waiting \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m seconds ...\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m         _LOGGER\u001b[38;5;241m.\u001b[39mdebug(msg, lock_id, lock_filename, poll_interval)\n\u001b[0;32m--> 267\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(poll_interval)\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# Something did go wrong, so decrement the counter.\u001b[39;00m\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context\u001b[38;5;241m.\u001b[39mlock_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context\u001b[38;5;241m.\u001b[39mlock_counter \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(\n",
    "    num_epochs=100,\n",
    "    train_dataloader=dataloader['train'],\n",
    "    valid_dataloader=dataloader['valid'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader['train']))['cause_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inference: 100%|██████████| 1/1 [00:01<00:00,  1.84s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'emotion': Array([0, 0, 2, 2, 1, 0, 0, 0], dtype=int32),\n",
       "  'cause': Array([1, 0, 1, 1, 0, 0, 0, 0], dtype=int32),\n",
       "  'span': defaultdict(list,\n",
       "              {2: [(0, Array(22, dtype=int32), Array(28, dtype=int32)),\n",
       "                (2, Array(1, dtype=int32), Array(15, dtype=int32))],\n",
       "               3: [(0, Array(22, dtype=int32), Array(28, dtype=int32)),\n",
       "                (2, Array(1, dtype=int32), Array(15, dtype=int32)),\n",
       "                (3, Array(1, dtype=int32), Array(3, dtype=int32))],\n",
       "               4: [(0, Array(22, dtype=int32), Array(28, dtype=int32)),\n",
       "                (2, Array(1, dtype=int32), Array(15, dtype=int32)),\n",
       "                (3, Array(1, dtype=int32), Array(3, dtype=int32))]})},\n",
       " {'emotion': Array([3, 0, 2], dtype=int32),\n",
       "  'cause': Array([1, 0, 1], dtype=int32),\n",
       "  'span': defaultdict(list,\n",
       "              {0: [(0, Array(1, dtype=int32), Array(7, dtype=int32))],\n",
       "               2: [(2, Array(1, dtype=int32), Array(3, dtype=int32))]})}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = trainer.predict(dataloader['train'])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval]: 100%|██████████| 1/1 [07:30<00:00, 450.14s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.valid_epoch(0, dataloader['valid'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotion-analysis-adVGJZXD-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
