{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internal Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX Backend:  gpu\n",
      "JAX Version:  0.4.23\n",
      "Python:  3.11.0 (main, Oct  4 2023, 22:00:02) [GCC 13.2.1 20230801]\n",
      "System:  posix.uname_result(sysname='Linux', nodename='archlinux', release='6.7.0-arch3-1', version='#1 SMP PREEMPT_DYNAMIC Sat, 13 Jan 2024 14:37:14 +0000', machine='x86_64')\n"
     ]
    }
   ],
   "source": [
    "# Find \".env\" file and add the package to $PATH\n",
    "import os, sys\n",
    "import typing as t\n",
    "from typing import Dict, TypeAlias, Any\n",
    "from dotenv import find_dotenv\n",
    "sys.path.append(os.path.dirname(find_dotenv()))\n",
    "\n",
    "# Use local package for modularity\n",
    "import emotion_analysis as ea\n",
    "from emotion_analysis import config\n",
    "from emotion_analysis.data.dataset import ECACDataset\n",
    "from emotion_analysis.model.trainer import TrainerModule\n",
    "from emotion_analysis.data.loader import DefaultDataLoader\n",
    "from emotion_analysis.model.pretrained import load_text_model\n",
    "from emotion_analysis.model.model import EmotionCauseTextModel\n",
    "from emotion_analysis.data.types import TrainSplit, DataSplit, SubTask\n",
    "from emotion_analysis.data.transform import DataTokenize, DataTransform, DataCollator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "External Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrm\n",
    "from jax import Array\n",
    "import jax.tree_util as tree_util\n",
    "from jax.tree_util import tree_structure\n",
    "from jax.typing import ArrayLike, DTypeLike\n",
    "import flax\n",
    "import flax.linen as nn\n",
    "import numpy as np\n",
    "import optax as opt\n",
    "import mlflow as mlf\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessors\n",
    "text_encoder_pretrained = load_text_model(config.model_repo, config.cache_dir)\n",
    "tokenizer = text_encoder_pretrained.tokenizer\n",
    "tokenize = DataTokenize( tokenizer,  max_seq_len=config.max_uttr_len)\n",
    "transform = DataTransform(tokenize, max_conv_len=config.max_conv_len)\n",
    "collator = DataCollator(transform)\n",
    "\n",
    "# Load data subsets\n",
    "dataset: Dict[DataSplit, ECACDataset] = ECACDataset.read_data(config.data_dir, config.subtask)\n",
    "ds_train, ds_valid, ds_test = *random_split(dataset['train'], [0.75, 0.25]), dataset['test']\n",
    "num_classes: int = dataset['train'].num_emotions\n",
    "\n",
    "# Train: drop_last=True to avoid JAX graph recompilation\n",
    "dataloader: t.Dict[TrainSplit, DataLoader[t.Dict[str, Array]]] = {\n",
    "    'train': DefaultDataLoader(ds_train,  shuffle=True, collate_fn=collator, drop_last=True),\n",
    "    'valid': DefaultDataLoader(ds_train, shuffle=False, collate_fn=collator),\n",
    "    'test' : DefaultDataLoader( ds_test, shuffle=False, collate_fn=collator),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jrm.PRNGKey(config.seed)\n",
    "key, trainer_key = jrm.split(key, 2)\n",
    "\n",
    "trainer = TrainerModule(\n",
    "    key=trainer_key,\n",
    "    finetune=config.finetune,\n",
    "    batch_size=config.batch_size,\n",
    "    max_conv_len=config.max_conv_len,\n",
    "    max_uttr_len=config.max_uttr_len,\n",
    "    text_model_repo=config.model_repo,\n",
    "    learning_rate=config.learning_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_jit(x, params, train, drop_key):\n",
    "    y= trainer.model.apply({ 'params': params }, **x, train=train, rngs={ 'dropout': drop_key })\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed = jax.jit(test_jit, static_argnames='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "for X in dataloader['valid']:\n",
    "    X = { 'input_ids': X['input_ids'], 'uttr_attn_mask': X['attention_mask'], 'conv_attn_mask': X['input_mask'] }\n",
    "    y = speed(X, trainer.state.params, True, key)\n",
    "    print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train only the classifier for now...\n",
    "should_freeze = lambda p, _: 'frozen' if 'text_encoder' in p else 'trainable'\n",
    "param_labels = flax.traverse_util.path_aware_map(should_freeze, params)\n",
    "tx = opt.multi_transform({ 'trainable': opt.adamw(2e-4), 'frozen': opt.set_to_zero() }, param_labels)\n",
    "opt_state = tx.init(params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotion-analysis-adVGJZXD-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
