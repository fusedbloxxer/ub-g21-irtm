{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internal Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/01/25 16:50:42 INFO mlflow.tracking.fluent: Experiment with name 'development' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX Backend:  gpu\n",
      "JAX Version:  0.4.23\n",
      "Python:  3.11.0 (main, Oct  5 2023, 23:57:12) [GCC 13.2.1 20230801]\n",
      "System:  posix.uname_result(sysname='Linux', nodename='archlinux', release='6.7.0-arch3-1', version='#1 SMP PREEMPT_DYNAMIC Sat, 13 Jan 2024 14:37:14 +0000', machine='x86_64')\n"
     ]
    }
   ],
   "source": [
    "# Find \".env\" file and add the package to $PATH\n",
    "import os, sys\n",
    "import typing as t\n",
    "from typing import Dict\n",
    "from dotenv import find_dotenv\n",
    "sys.path.append(os.path.dirname(find_dotenv()))\n",
    "\n",
    "# Use local package for modularity\n",
    "from emotion_analysis import config\n",
    "from emotion_analysis.utils.weight import INSWeight\n",
    "from emotion_analysis.model.pretrained import load_text_model\n",
    "from emotion_analysis.model.trainer import TrainerModule\n",
    "from emotion_analysis.data.dataset import ECACDataset\n",
    "from emotion_analysis.data.loader import DefaultDataLoader\n",
    "from emotion_analysis.data.types import EmotionCauseEncoding\n",
    "from emotion_analysis.data.types import TrainSplit, DataSplit\n",
    "from emotion_analysis.data.transform import TokenizeTransform, EncodeTransform, CollateTransform, Transform, WeightTransform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "External Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax\n",
    "import flax.linen as nn\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrm\n",
    "import jax.tree_util as tree_util\n",
    "import mlflow as mlf\n",
    "import seaborn as sea\n",
    "import numpy as np\n",
    "import optax as opt\n",
    "from jax import Array\n",
    "from jax.tree_util import tree_structure\n",
    "from jax.typing import ArrayLike, DTypeLike\n",
    "from numpy import ndarray\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data subsets in-memory\n",
    "dataset: Dict[DataSplit, ECACDataset] = ECACDataset.read_data(config.data_dir, config.subtask)\n",
    "ds_train, ds_valid, ds_test = *random_split(dataset['train'], [0.75, 0.25]), dataset['test']\n",
    "\n",
    "# Extract relevant statistics\n",
    "num_classes: int = dataset['train'].num_emotions\n",
    "emotion_labels = dataset['train'].emotion_labels\n",
    "emotion_weights = INSWeight(num_classes, emotion_labels)\n",
    "\n",
    "# Load pretrained model\n",
    "text_encoder_pretrained = load_text_model(config.model_repo, config.cache_dir)\n",
    "tokenizer = text_encoder_pretrained.tokenizer\n",
    "\n",
    "# Compose data transformations\n",
    "tokenize = TokenizeTransform(tokenizer, max_seq_len=config.max_uttr_len)\n",
    "encode = EncodeTransform(tokenize, max_conv_len=config.max_conv_len)\n",
    "weight = WeightTransform(emotion_weights)\n",
    "collator = CollateTransform(Transform.chain(encode, weight))\n",
    "\n",
    "# Train: drop_last=True to avoid JAX graph recompilation\n",
    "dataloader: t.Dict[TrainSplit, DataLoader[EmotionCauseEncoding]] = {\n",
    "    'train': DefaultDataLoader(ds_train,  shuffle=True, collate_fn=collator, drop_last=True),\n",
    "    'valid': DefaultDataLoader(ds_valid, shuffle=False, collate_fn=collator),\n",
    "    'test' : DefaultDataLoader( ds_test, shuffle=False, collate_fn=collator),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25 16:51:46.734954: W external/tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.37GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    }
   ],
   "source": [
    "key = jrm.PRNGKey(config.seed)\n",
    "key, trainer_key = jrm.split(key, 2)\n",
    "trainer = TrainerModule(\n",
    "    key=trainer_key,\n",
    "    finetune=config.finetune,\n",
    "    batch_size=config.batch_size,\n",
    "    max_conv_len=config.max_conv_len,\n",
    "    max_uttr_len=config.max_uttr_len,\n",
    "    text_model_repo=config.model_repo,\n",
    "    learning_rate=config.learning_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inference: 100%|██████████| 515/515 [08:40<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "pred = trainer.predict(dataloader['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(pred)):\n",
    "    print(pred[i]['span'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[train][epoch: 0]:  45%|████▌     | 233/515 [01:59<02:24,  1.95it/s]\n",
      "[training]:   0%|          | 0/5 [01:59<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/storage/git/ub-g21-irtm/emotion-analysis/emotion_analysis/model/trainer.py:284\u001b[0m, in \u001b[0;36mTrainerModule.train\u001b[0;34m(self, train_dataloader, valid_dataloader, tags, num_epochs)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;66;03m# Perform train & valid at each step\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m trange(num_epochs, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[training]\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_epoch(epoch, valid_dataloader)\n",
      "File \u001b[0;32m/mnt/storage/git/ub-g21-irtm/emotion-analysis/emotion_analysis/model/trainer.py:236\u001b[0m, in \u001b[0;36mTrainerModule.train_epoch\u001b[0;34m(self, epoch, dataloader)\u001b[0m\n\u001b[1;32m    234\u001b[0m pred \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcause\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m][conv_mask, :]\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    235\u001b[0m refs \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcause_labels\u001b[39m\u001b[38;5;124m'\u001b[39m][conv_mask]\n\u001b[0;32m--> 236\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_f1_cause\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreferences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# Compute emotion predictions\u001b[39;00m\n\u001b[1;32m    239\u001b[0m pred \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memotion\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m][conv_mask, :]\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/mnt/storage/git/ub-g21-irtm/emotion-analysis/emotion_analysis/model/metrics.py:56\u001b[0m, in \u001b[0;36mF1Metric.update\u001b[0;34m(self, predictions, references)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, predictions: Array, references: Array) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf1_score\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreferences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreferences\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/storage/.cache/pypoetry/virtualenvs/emotion-analysis-DIRhFH6i-py3.11/lib/python3.11/site-packages/evaluate/module.py:515\u001b[0m, in \u001b[0;36mEvaluationModule.add_batch\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(column) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    514\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enforce_nested_string_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselected_feature_format[key], column[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 515\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselected_feature_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter\u001b[38;5;241m.\u001b[39mwrite_batch(batch)\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n",
      "File \u001b[0;32m/mnt/storage/.cache/pypoetry/virtualenvs/emotion-analysis-DIRhFH6i-py3.11/lib/python3.11/site-packages/datasets/features/features.py:1911\u001b[0m, in \u001b[0;36mFeatures.encode_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m   1909\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn mismatch between batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mset\u001b[39m(batch)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and features \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1910\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, column \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m-> 1911\u001b[0m     column \u001b[38;5;241m=\u001b[39m \u001b[43mcast_to_python_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1912\u001b[0m     encoded_batch[key] \u001b[38;5;241m=\u001b[39m [encode_nested_example(\u001b[38;5;28mself\u001b[39m[key], obj) \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m column]\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m encoded_batch\n",
      "File \u001b[0;32m/mnt/storage/.cache/pypoetry/virtualenvs/emotion-analysis-DIRhFH6i-py3.11/lib/python3.11/site-packages/datasets/features/features.py:447\u001b[0m, in \u001b[0;36mcast_to_python_objects\u001b[0;34m(obj, only_1d_for_numpy, optimize_list_casting)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcast_to_python_objects\u001b[39m(obj: Any, only_1d_for_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, optimize_list_casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    428\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;124;03m    Cast numpy/pytorch/tensorflow/pandas objects to python lists.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;124;03m    It works recursively.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;124;03m        casted_obj: the casted object\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 447\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_cast_to_python_objects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_1d_for_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_1d_for_numpy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize_list_casting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimize_list_casting\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/mnt/storage/.cache/pypoetry/virtualenvs/emotion-analysis-DIRhFH6i-py3.11/lib/python3.11/site-packages/datasets/features/features.py:347\u001b[0m, in \u001b[0;36m_cast_to_python_objects\u001b[0;34m(obj, only_1d_for_numpy, optimize_list_casting)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(obj)[()], \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m only_1d_for_numpy \u001b[38;5;129;01mor\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    350\u001b[0m         [\n\u001b[1;32m    351\u001b[0m             _cast_to_python_objects(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    357\u001b[0m     )\n",
      "File \u001b[0;32m/mnt/storage/.cache/pypoetry/virtualenvs/emotion-analysis-DIRhFH6i-py3.11/lib/python3.11/site-packages/jax/_src/array.py:390\u001b[0m, in \u001b[0;36mArrayImpl.__array__\u001b[0;34m(self, dtype, context)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 390\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_value\u001b[49m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m/mnt/storage/.cache/pypoetry/virtualenvs/emotion-analysis-DIRhFH6i-py3.11/lib/python3.11/site-packages/jax/_src/profiler.py:336\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    335\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m/mnt/storage/.cache/pypoetry/virtualenvs/emotion-analysis-DIRhFH6i-py3.11/lib/python3.11/site-packages/jax/_src/array.py:589\u001b[0m, in \u001b[0;36mArrayImpl._value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npy_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    588\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fully_replicated:\n\u001b[0;32m--> 589\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npy_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_single_device_array_to_np_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npy_value\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npy_value)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(\n",
    "    num_epochs=5,\n",
    "    train_dataloader=dataloader['train'],\n",
    "    valid_dataloader=dataloader['valid'],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotion-analysis-adVGJZXD-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
